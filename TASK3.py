from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report

iris = load_iris()
X, y = iris.data, iris.target


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

gnb = GaussianNB()
gnb.fit(X_train, y_train)
y_pred_gnb = gnb.predict(X_test)

print("ðŸ”¹ GaussianNB Accuracy:", accuracy_score(y_test, y_pred_gnb))
print("ðŸ”¹ GaussianNB Report:\n", classification_report(y_test, y_pred_gnb))

lr = LogisticRegression(max_iter=200)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

print("ðŸ”¹ Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)

print("ðŸ”¹ Decision Tree Accuracy:", accuracy_score(y_test, y_pred_dt))
#Same Accuracy for Decision Tree and Logistic Regression ,reason for this could be that the dataset
#  is relatively simple and both models are able to capture the underlying patterns 
# effectively.
